# AI-Voice-Assistant

# 🎙 30 Days of AI Voice Agents

Welcome to my **30 Days of AI Voice Agents** challenge!  
This repository documents my day-by-day journey of building AI-powered voice agents — from basic speech recognition to a fully functional, interactive conversational assistant.

---

## 📌 Project Overview
The main goal of this challenge is to explore and implement AI voice technologies step-by-step over 30 days, leading to a **final, polished voice agent** capable of:
- Listening to speech in real-time 🎤
- Understanding and processing language 🧠
- Responding naturally using AI-generated voices 🔊

Technologies explored include:
- **Speech-to-Text (STT)** using AssemblyAI
- **Large Language Model (LLM)** integration
- **Text-to-Speech (TTS)** using Murf AI
- **FastAPI** backend
- **HTML, CSS, JavaScript** frontend

---

## 🚀 Features in the Project
✅ Real-time Voice Input (Start/Stop Recording)  
✅ Speech-to-Text Conversion  
✅ AI Chatbot with Contextual Memory  
✅ Text-to-Speech Voice Output  
✅ User-friendly Frontend with chat history and status indicators  
✅ Error Handling & fallback voice messages  

---

## 🛠 Installation & Setup

### 1️⃣ Clone the Repository
git clone https://github.com/<your-username>/30-days-ai-voice-agent.git
cd 30-days-ai-voice-agent/final-project
````

### 2️⃣ Install Dependencies

```bash
pip install -r requirements.txt

### 3️⃣ Set Up Environment Variables

Create a .env file and add:

ASSEMBLYAI_API_KEY=your_api_key_here
MURF_API_KEY=your_api_key_here
GOOGLE_API_KEY=your_api_key_here

### 4️⃣ Run the Application

uvicorn main:app --reload

Open your browser and visit:

http://127.0.0.1:8000

---



## 🧠 Learnings & Skills Gained

* Working with Speech APIs (AssemblyAI, Murf AI)
* Building interactive UIs for voice agents
* Integrating LLMs into conversational flows
* Deploying FastAPI applications
* Implementing error handling & fallback strategies

---

## 📜 License

This project is licensed under the MIT License — feel free to fork and experiment!

---



